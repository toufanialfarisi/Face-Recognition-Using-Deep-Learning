{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'dataset/datasets/'\n",
    "images = glob.glob(dataset+\"*/*\")\n",
    "np.random.shuffle(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error dataset/datasets/toufan/6.jpg\n",
      "error dataset/datasets/zul/18.jpg\n",
      "error dataset/datasets/surahmin/15.png\n",
      "error dataset/datasets/cezar/18.jpg\n",
      "error dataset/datasets/cezar/13.jpg\n",
      "error dataset/datasets/cezar/21.jpg\n",
      "error dataset/datasets/cezar/14.jpg\n",
      "error dataset/datasets/cezar/17.jpg\n",
      "error dataset/datasets/cezar/5.jpg\n"
     ]
    }
   ],
   "source": [
    "data_face = []\n",
    "for i in images:\n",
    "    image = face_recognition.load_image_file(i)\n",
    "    face_locations = face_recognition.face_locations(image)\n",
    "    try:\n",
    "        (top, right, bottom, left) = face_locations[0]\n",
    "        img_ = image[top:bottom, left:right, :]\n",
    "        img_ = cv2.resize(img_, (100, 100))\n",
    "        data_face.append(img_)\n",
    "    except:\n",
    "        print('error', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "f = open('face_images.pickle', 'wb')\n",
    "f.write(pickle.dumps(data_face))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_flip = []\n",
    "for j in data_face:\n",
    "    for k in range(2):\n",
    "        flip = cv2.flip(j, k)\n",
    "        face_flip.append(flip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_aug_img = []\n",
    "for a in face_flip:\n",
    "    (h, w) = a.shape[:2]\n",
    "    center = (h // 2, w // 2)\n",
    "    for deg in range(len(face_flip)):\n",
    "        M = cv2.getRotationMatrix2D(center, deg, 1.0)\n",
    "        rotated = cv2.warpAffine(a, M, (w, h))\n",
    "        final_aug_img.append(rotated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(final_aug_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('img',data_face[100])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aug_img = []\n",
    "# for j in images[:]:\n",
    "#     gbr = cv2.imread(j)\n",
    "#     gbr = cv2.resize(gbr, (32,32))\n",
    "#     (h, w) = gbr.shape[:2]\n",
    "#     center = (h // 2, w // 2)\n",
    "#     for jj in range(len(images)):\n",
    "#         M = cv2.getRotationMatrix2D(center, jj, 1.0)\n",
    "#         rotated = cv2.warpAffine(gbr, M, (w, h))\n",
    "#         aug_img.append(rotated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(fa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imshow('img', img_)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kita load datanya ke memory\n",
    "image_data = []\n",
    "label_data = []\n",
    "for i, ii in zip(aug_img, images):\n",
    "    image_data.append(i)\n",
    "    lbl = ii.split('/')[-2]\n",
    "    label_data.append(lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.asarray(image_data)\n",
    "y = np.asarray(label_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.float32(x)\n",
    "x = x / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "lb = LabelBinarizer()\n",
    "y_en = lb.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y_en, test_size=0.25, random_state=42)\n",
    "# cek apakah sudah benar atau belum pemecaannya\n",
    "print('x_train : ',x_train.shape)\n",
    "print('x_test  : ', x_test.shape)\n",
    "print('y_train : ', y_train.shape)\n",
    "print('y_test  : ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras model\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
    "from keras.models import Input, Model, Sequential\n",
    "# mulai membuat arsitektur NN dengan tipe fully connected layer\n",
    "from keras.layers import BatchNormalization, Dropout\n",
    "input_layer    = Input(shape=(x_train.shape[1:]))\n",
    "\n",
    "batch = BatchNormalization(input_shape=x_train.shape[1:])(input_layer)\n",
    "conv = Conv2D(16, kernel_size=(5,5), padding='SAME', activation='relu', name='conv_layer_1')(batch)\n",
    "pool = MaxPool2D(pool_size=(4,4), name='maxpooling_1')(conv)\n",
    "drop = Dropout(0.25)(pool)\n",
    "\n",
    "batch1 = BatchNormalization(input_shape=x_train.shape[1:])(drop)\n",
    "conv1 = Conv2D(16, kernel_size=(5,5), padding='SAME', activation='relu', name='conv_layer_2')(batch1)\n",
    "pool1 = MaxPool2D(pool_size=(4,4), name='maxpooing_2')(conv1)\n",
    "drop1 = Dropout(0.25)(pool1)\n",
    "\n",
    "flatten_layer = Flatten(name='flatten_layer')(drop1)\n",
    "full_con_layer = Dense(512, activation='relu', name='fully_connected_layer')(flatten_layer)\n",
    "full_con_layer1 = Dense(128, activation='relu', name='fully_connected_layer_1')(full_con_layer)\n",
    "drop3 = Dropout(0.5)(full_con_layer1)\n",
    "output_layer = Dense(6, activation='softmax', name='output_layer')(drop3)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "Tensorboard = keras.callbacks.TensorBoard(log_dir='./keras-logs-2', histogram_freq=0,  write_graph=True, write_images=False)\n",
    "# Save the checkpoint in the /output folder\n",
    "# filepath = \"/keras-ckpt/mnist-cnn-best.hdf5\"\n",
    "\n",
    "# # Keep only a single checkpoint, the best over test accuracy.\n",
    "# checkpoint = keras.callbacks.ModelCheckpoint(filepath,\n",
    "#                             monitor='val_acc',\n",
    "#                             verbose=1,\n",
    "#                             save_best_only=True,\n",
    "#                             mode='max')\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "opt = SGD(lr=2)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=5, min_lr=0.001)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, \n",
    "                    batch_size=32, epochs=890,\n",
    "                   validation_data=[x_test, y_test], \n",
    "                    callbacks=[Tensorboard, reduce_lr])\n",
    "model.save('roni_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nilai-nilai loss-nya\n",
    "loss = history.history['loss']\n",
    "\n",
    "# nilai-nilai val_loss-nya\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# nilai-nilai akurasi-nya\n",
    "acc = history.history['acc']\n",
    "\n",
    "# nilai-nilai val_acc-nya\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "# menentukan sumbu x nya dari 0 sampai dengan banyaknya jumlah nilai loss/acc\n",
    "sumbu_x = np.arange(0, len(loss))\n",
    "\n",
    "# memasukan library plotting (matplotlib)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# grafik plot untuk melihat loss\n",
    "plt.figure(figsize=(15,3))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(sumbu_x, loss, label='loss')\n",
    "plt.plot(sumbu_x, val_loss, label='val_loss')\n",
    "plt.legend()\n",
    "\n",
    "# grafik plot untuk melihat akurasinya\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(sumbu_x, acc, label='acc')\n",
    "plt.plot(sumbu_x, val_acc, label='val_acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:lab]",
   "language": "python",
   "name": "conda-env-lab-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
